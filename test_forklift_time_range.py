#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš› KIRII ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ¢ãƒ‡ãƒ« - æ™‚é–“ç¯„å›²ãƒ†ã‚¹ãƒˆ
============================================================
ç‰¹å®šæ™‚é–“ç¯„å›²ï¼ˆ3:02-4:30ï¼‰ã§ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºã‚’ãƒ†ã‚¹ãƒˆ
"""

import cv2
import numpy as np
from ultralytics import YOLO
import os
import time
from pathlib import Path

class ForkliftTimeRangeTester:
    def __init__(self, model_path="forklift_model.pt"):
        """ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ™‚é–“ç¯„å›²ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸš› KIRII ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ¢ãƒ‡ãƒ« - æ™‚é–“ç¯„å›²ãƒ†ã‚¹ãƒˆ")
        print("=" * 60)
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        print(f"ğŸ“¦ ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {model_path}")
        try:
            self.model = YOLO(model_path)
            print("âœ… ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        # ã‚¯ãƒ©ã‚¹åè¨­å®š
        self.class_names = {
            0: "forklift",
            1: "person", 
            2: "pallet",
            3: "box",
            4: "warning_sign",
            5: "safety_cone"
        }
        
        # æ¤œå‡ºè¨­å®š
        self.confidence_threshold = 0.1  # 10%
        self.iou_threshold = 0.3
        
        # æ™‚é–“ç¯„å›²è¨­å®šï¼ˆç§’ï¼‰
        self.start_time = 3 * 60 + 2  # 3:02 (182ç§’)
        self.end_time = 4 * 60 + 30   # 4:30 (270ç§’)
        
    def test_video_time_range(self, video_path):
        """ç‰¹å®šæ™‚é–“ç¯„å›²ã§ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ¬ æ™‚é–“ç¯„å›²ãƒ†ã‚¹ãƒˆé–‹å§‹: {video_path}")
        print(f"â° ãƒ†ã‚¹ãƒˆæ™‚é–“ç¯„å›²: {self.start_time//60}:{self.start_time%60:02d} - {self.end_time//60}:{self.end_time%60:02d}")
        
        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        if not os.path.exists(video_path):
            print(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
            return
        
        # å‹•ç”»èª­ã¿è¾¼ã¿
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}")
            return
        
        # å‹•ç”»æƒ…å ±å–å¾—
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"ğŸ“Š å‹•ç”»æƒ…å ±:")
        print(f"  - è§£åƒåº¦: {width}x{height}")
        print(f"  - FPS: {fps}")
        print(f"  - ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}")
        print(f"  - ç·æ™‚é–“: {total_frames/fps:.1f}ç§’")
        
        # æ™‚é–“ç¯„å›²ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã«å¤‰æ›
        start_frame = int(self.start_time * fps)
        end_frame = int(self.end_time * fps)
        
        print(f"ğŸ“ˆ å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²: {start_frame} - {end_frame}")
        print(f"ğŸ“ˆ å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {end_frame - start_frame}")
        
        # å‡ºåŠ›å‹•ç”»è¨­å®š
        output_path = f"forklift_detection_3min02_4min30_{Path(video_path).stem}.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        # æ¤œå‡ºçµ±è¨ˆ
        detection_stats = {
            'total_frames': 0,
            'frames_with_forklift': 0,
            'total_forklifts': 0,
            'start_time': time.time()
        }
        
        print(f"\nğŸ¯ ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºé–‹å§‹ï¼ˆæ™‚é–“ç¯„å›²: {self.start_time//60}:{self.start_time%60:02d}-{self.end_time//60}:{self.end_time%60:02d}ï¼‰...")
        print(f"ğŸ’¡ æ¤œå‡ºé–¾å€¤: {self.confidence_threshold} (10%)")
        
        frame_count = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            current_time = frame_count / fps
            
            # æ™‚é–“ç¯„å›²å¤–ã¯ã‚¹ã‚­ãƒƒãƒ—
            if current_time < self.start_time:
                continue
            if current_time > self.end_time:
                break
            
            detection_stats['total_frames'] += 1
            
            # é€²æ—è¡¨ç¤º
            if frame_count % 30 == 0:  # 30ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨
                progress = ((current_time - self.start_time) / (self.end_time - self.start_time)) * 100
                elapsed = time.time() - detection_stats['start_time']
                fps_processed = detection_stats['total_frames'] / elapsed if elapsed > 0 else 0
                print(f"ğŸ“ˆ é€²æ—: {progress:.1f}% (æ™‚é–“: {current_time//60:.0f}:{current_time%60:02.0f}) - {fps_processed:.1f} FPS")
            
            # ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡º
            results = self.model(frame, conf=self.confidence_threshold, iou=self.iou_threshold, verbose=False)
            
            # æ¤œå‡ºçµæœæç”»
            annotated_frame = frame.copy()
            forklifts_in_frame = 0
            
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        # åº§æ¨™å–å¾—
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = box.conf[0].cpu().numpy()
                        class_id = int(box.cls[0].cpu().numpy())
                        
                        # ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºã®å ´åˆ
                        if class_id == 0:  # forklift
                            forklifts_in_frame += 1
                            detection_stats['total_forklifts'] += 1
                            
                            # ä¿¡é ¼åº¦ã«å¿œã˜ã¦è‰²ã‚’å¤‰ãˆã‚‹
                            if confidence > 0.5:
                                color = (0, 255, 0)  # ç·‘è‰²ï¼ˆé«˜ä¿¡é ¼åº¦ï¼‰
                            elif confidence > 0.3:
                                color = (0, 255, 255)  # é»„è‰²ï¼ˆä¸­ä¿¡é ¼åº¦ï¼‰
                            else:
                                color = (0, 165, 255)  # ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆä½ä¿¡é ¼åº¦ï¼‰
                            
                            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
                            cv2.rectangle(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                            
                            # ãƒ©ãƒ™ãƒ«æç”»
                            label = f"Forklift: {confidence:.2f}"
                            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                            cv2.rectangle(annotated_frame, (int(x1), int(y1) - label_size[1] - 10), 
                                        (int(x1) + label_size[0], int(y1)), color, -1)
                            cv2.putText(annotated_frame, label, (int(x1), int(y1) - 5), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆãŒæ¤œå‡ºã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            if forklifts_in_frame > 0:
                detection_stats['frames_with_forklift'] += 1
                print(f"ğŸš› æ™‚é–“ {current_time//60:.0f}:{current_time%60:02.0f} (ãƒ•ãƒ¬ãƒ¼ãƒ {frame_count}): {forklifts_in_frame}å€‹ã®ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆã‚’æ¤œå‡º")
            
            # çµ±è¨ˆæƒ…å ±ã‚’ç”»é¢ã«è¡¨ç¤º
            stats_text = f"Time: {current_time//60:.0f}:{current_time%60:02.0f}"
            cv2.putText(annotated_frame, stats_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            forklift_text = f"Forklifts: {forklifts_in_frame}"
            cv2.putText(annotated_frame, forklift_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            frame_text = f"Frame: {frame_count}"
            cv2.putText(annotated_frame, frame_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # å‡ºåŠ›å‹•ç”»ã«æ›¸ãè¾¼ã¿
            out.write(annotated_frame)
        
        # ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
        cap.release()
        out.release()
        
        # çµæœè¡¨ç¤º
        elapsed_time = time.time() - detection_stats['start_time']
        print(f"\nğŸ‰ æ™‚é–“ç¯„å›²ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ†ã‚¹ãƒˆå®Œäº†!")
        print(f"ğŸ“Š æ¤œå‡ºçµæœ:")
        print(f"  - å‡¦ç†æ™‚é–“: {elapsed_time:.1f}ç§’")
        print(f"  - å‡¦ç†FPS: {detection_stats['total_frames']/elapsed_time:.1f}")
        print(f"  - å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {detection_stats['total_frames']}")
        print(f"  - ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ : {detection_stats['frames_with_forklift']}")
        print(f"  - ç·ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºæ•°: {detection_stats['total_forklifts']}")
        print(f"  - æ¤œå‡ºç‡: {(detection_stats['frames_with_forklift']/detection_stats['total_frames'])*100:.1f}%")
        
        print(f"\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
        print(f"  - {output_path}")
        
        return output_path, detection_stats

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ™‚é–“ç¯„å›²ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    tester = ForkliftTimeRangeTester("forklift_model.pt")
    
    # ãƒ†ã‚¹ãƒˆç”¨å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«
    video_path = '/Users/sakonhiroki/Desktop/screeshot/ç”»é¢åéŒ² 2025-07-31 11.27.02.mov'
    
    # å‹•ç”»ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    output_path, stats = tester.test_video_time_range(video_path)
    
    print(f"\nğŸš› æ™‚é–“ç¯„å›²ãƒ•ã‚©ãƒ¼ã‚¯ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ†ã‚¹ãƒˆå®Œäº†!")
    print(f"ğŸ“ çµæœå‹•ç”»: {output_path}")

if __name__ == "__main__":
    main() 